import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import pandas as pd
from typing import Dict, List, Optional
from pandas.plotting import table  # Import for rendering DataFrame as a table


def plot_top_n_accuracies(
        accuracies: Dict[str, List[float]],
        save_path: Optional[str] = None,
        palette: Optional[str] = "Set2",
        vectorizer_name: Optional[str] = None,
) -> None:
    """
    Plot cumulative top-N accuracies for a single vectorizer with a modern style.

    :param accuracies: Output from Benchmark.get_accuracies(n), i.e., Dict[cohort → List[accuracy@1...n]]
    :param title: Plot title.
    :param save_path: If provided, save the figure to this path instead of showing it.
    :param palette: Optional seaborn color palette name.
    """
    sns.set(style="whitegrid", font_scale=1.2)
    plt.figure(figsize=(10, 6))

    n = len(next(iter(accuracies.values())))
    x = list(range(1, n + 1))

    color_palette = sns.color_palette(palette, n_colors=len(accuracies))

    for (cohort_name, acc_list), color in zip(accuracies.items(), color_palette):
        plt.plot(x, acc_list, marker='o', linewidth=2.5, label=cohort_name, color=color)

    title: str = "Top-N Accuracy per Cohort " + vectorizer_name if vectorizer_name else "Top-N Accuracy per Cohort"

    plt.title(title, fontsize=16, fontweight='bold')
    plt.xlabel("Top-N", fontsize=13)
    plt.ylabel("Cumulative Accuracy", fontsize=13)
    plt.xticks(x)
    plt.ylim(0, 1.05)
    plt.grid(True, linestyle="--", alpha=0.6)
    plt.legend(title="Cohort", fontsize=11, title_fontsize=12, loc="lower right")
    plt.tight_layout()

    if save_path:
        plt.savefig(save_path + "/" + "overall_" + vectorizer_name + ".png", dpi=300)
        plt.close()
    else:
        plt.show()


def summarize_top1_accuracies(all_accuracies: Dict[str, Dict[str, List[float]]], save_path=None) -> pd.DataFrame:
    """
    Summarize top-1 accuracies for multiple vectorizers in a table format.

    :param all_accuracies: Dict[vectorizer_name → Dict[cohort → List[float (length N)]]]
    :param save_path: If provided, save the summary table as an image in the specified directory.
    :return: DataFrame with cohorts as rows, vectorizers as columns, and top-1 accuracies as values.
    """
    # Create a DataFrame with cohorts as rows and vectorizers as columns
    summary = {
        vectorizer_name: {cohort: round(acc_list[0], 2) for cohort, acc_list in cohort_dict.items()}
        for vectorizer_name, cohort_dict in all_accuracies.items()
    }
    df_summary = pd.DataFrame(summary).sort_index()

    # Add bold formatting for the largest entry per row
    def format_bold_row(row):
        max_value = row.max()
        return [f"**{value}**" if value == max_value else f"{value}" for value in row]

    formatted_data = df_summary.apply(format_bold_row, axis=1).to_list()
    df_summary_formatted = pd.DataFrame(formatted_data, index=df_summary.index, columns=df_summary.columns)

    if save_path:
        plt.figure(figsize=(12, 6))
        ax = plt.gca()
        ax.axis('off')  # Turn off the axis
        tbl = table(ax, df_summary_formatted, loc='center', cellLoc='center')  # Render table
        tbl.auto_set_font_size(False)
        tbl.set_fontsize(10)
        tbl.scale(1.2, 1.2)  # Scale table for better readability
        plt.savefig(f"{save_path}/summary_table.png", dpi=300, bbox_inches='tight', pad_inches=0.1)
        plt.close()

    return df_summary


def plot_topn_per_cohort(
        all_accuracies: Dict[str, Dict[str, List[float]]],
        title_prefix: str = "Top-N Accuracy",
        palette: Optional[str] = "Set2",
        save_path: Optional[str] = None
) -> None:
    """
    Plot Top-N accuracy curves per cohort comparing multiple vectorizers.

    :param all_accuracies: Dict[vectorizer_name → Dict[cohort → List[float]]]
    :param title_prefix: Prefix for the plot titles.
    :param palette: Seaborn color palette.
    """
    sns.set(style="whitegrid", font_scale=1.1)

    # Get all cohorts from any one vectorizer
    example_vectorizer = next(iter(all_accuracies.values()))
    cohorts = list(example_vectorizer.keys())
    n = len(next(iter(example_vectorizer.values())))  # Number of top-N levels
    x = list(range(1, n + 1))

    for cohort in cohorts:
        plt.figure(figsize=(10, 6))
        color_palette = sns.color_palette(palette, n_colors=len(all_accuracies))

        for (vectorizer_name, vectorizer_accuracies), color in zip(all_accuracies.items(), color_palette):
            y = vectorizer_accuracies[cohort]
            plt.plot(x, y, marker='o', label=vectorizer_name, linewidth=2.5, color=color)

        plt.title(f"{title_prefix}: {cohort}", fontsize=15, fontweight='bold')
        plt.xlabel("Top-N", fontsize=12)
        plt.ylabel("Cumulative Accuracy", fontsize=12)
        plt.xticks(x)
        plt.ylim(0, 1.05)
        plt.grid(True, linestyle="--", alpha=0.6)
        plt.legend(title="Vectorizer", fontsize=10, title_fontsize=11, loc="lower right")
        plt.tight_layout()
        if save_path:
            plt.savefig(save_path + "/" + cohort + ".png", dpi=300)
            plt.close()
        else:
            plt.show()


def plot_precision_recall_curves(
        pr_results: Dict[str, Dict[str, List[float]]],
        save_path: Optional[str] = None,
        palette: Optional[str] = "Set2",
) -> None:
    """
    Plot Precision-Recall curves for each cohort and display the AUC in the legend.

    :param pr_results: Output from Benchmark.get_precision_recall(), i.e., Dict[cohort → {'precision': [...], 'recall': [...], 'thresholds': [...]}]
    :param save_path: If provided, save the figure to this path instead of showing it.
    :param palette: Optional seaborn color palette name.
    """
    sns.set(style="whitegrid", font_scale=1.2)
    plt.figure(figsize=(10, 6))
    color_palette = sns.color_palette(palette, n_colors=len(pr_results))

    for (cohort_name, metrics), color in zip(pr_results.items(), color_palette):
        precision = metrics.get("precision", [])
        recall = metrics.get("recall", [])
        if not precision or not recall:
            continue
        # Compute AUC using trapezoidal rule: area under Precision-Recall curve
        auc = np.trapz(precision, recall)
        plt.plot(
            recall,
            precision,
            marker='o',
            linewidth=2.5,
            label=f"{cohort_name} (AUC={auc:.2f})",
            color=color
        )

    plt.title("Precision-Recall Curve per Cohort", fontsize=16, fontweight='bold')
    plt.xlabel("Recall", fontsize=13)
    plt.ylabel("Precision", fontsize=13)
    plt.xlim(0, 1.05)
    plt.ylim(0, 1.05)
    plt.grid(True, linestyle="--", alpha=0.6)
    plt.legend(title="Cohort", fontsize=11, title_fontsize=12, loc="lower left")
    plt.tight_layout()

    if save_path:
        plt.savefig(f"{save_path}/precision_recall_curves.png", dpi=300)
        plt.close()
    else:
        plt.show()


pr_openai = {'GERAS-I': {'precision': [1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.6666666666666666, 0.5, 0.3333333333333333, 0.2857142857142857, 0.2857142857142857, 0.2857142857142857, 0.2857142857142857, 0.2857142857142857, 0.3, 0.2727272727272727, 0.3333333333333333, 0.3076923076923077, 0.2857142857142857, 0.25, 0.22727272727272727, 0.2, 0.18518518518518517, 0.14705882352941177, 0.12195121951219512, 0.10204081632653061, 0.10344827586206896, 0.08955223880597014, 0.0759493670886076, 0.06451612903225806, 0.06086956521739131, 0.058823529411764705, 0.05228758169934641, 0.045454545454545456, 0.038461538461538464, 0.03361344537815126, 0.03076923076923077, 0.027586206896551724, 0.024464831804281346, 0.021798365122615803, 0.02, 0.018223234624145785, 0.016632016632016633, 0.018726591760299626, 0.016722408026755852, 0.015384615384615385, 0.013966480446927373, 0.01278772378516624, 0.0117096018735363, 0.011554621848739496, 0.010576923076923078, 0.009674582233948988, 0.009561752988047808, 0.008759124087591242, 0.008855585831062671, 0.008934269304403318, 0.008383233532934131, 0.0077951002227171495, 0.007391763463569166, 0.007074279939363315, 0.00674373795761079, 0.0068997240110395585, 0.006590509666080844, 0.006347862886161659, 0.006124948958758677, 0.005957108816521049, 0.0058162078324932144, 0.0057186427754479605, 0.005567928730512249, 0.005492493592090809, 0.00539568345323741, 0.005341880341880342, 0.005277973258268825, 0.0052173913043478265, 0.005172413793103448, 0.005154639175257732, 0.005140507196710075, 0.00513347022587269, 0.005128205128205128, 0.005126452494873548, 0.005124701059104886, 0.005122950819672131], 'recall': [0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.13333333333333333, 0.13333333333333333, 0.13333333333333333, 0.13333333333333333, 0.13333333333333333, 0.13333333333333333, 0.13333333333333333, 0.13333333333333333, 0.2, 0.2, 0.26666666666666666, 0.26666666666666666, 0.26666666666666666, 0.26666666666666666, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.4, 0.4, 0.4, 0.4, 0.4666666666666667, 0.5333333333333333, 0.5333333333333333, 0.5333333333333333, 0.5333333333333333, 0.5333333333333333, 0.5333333333333333, 0.5333333333333333, 0.5333333333333333, 0.5333333333333333, 0.5333333333333333, 0.5333333333333333, 0.5333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.8, 0.8, 0.8666666666666667, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'thresholds': [0.6598943306834302, 0.6532638370496305, 0.6466333434158309, 0.6400028497820311, 0.6333723561482315, 0.6267418625144319, 0.6201113688806322, 0.6134808752468326, 0.6068503816130328, 0.6002198879792332, 0.5935893943454336, 0.5869589007116339, 0.5803284070778343, 0.5736979134440345, 0.5670674198102349, 0.5604369261764353, 0.5538064325426356, 0.5471759389088359, 0.5405454452750362, 0.5339149516412366, 0.527284458007437, 0.5206539643736372, 0.5140234707398376, 0.5073929771060379, 0.5007624834722383, 0.49413198983843865, 0.48750149620463895, 0.48087100257083926, 0.4742405089370396, 0.46761001530324, 0.46097952166944034, 0.45434902803564065, 0.44771853440184095, 0.4410880407680413, 0.4344575471342417, 0.427827053500442, 0.42119655986664234, 0.41456606623284264, 0.407935572599043, 0.40130507896524337, 0.3946745853314437, 0.38804409169764403, 0.38141359806384434, 0.3747831044300447, 0.368152610796245, 0.36152211716244537, 0.3548916235286457, 0.34826112989484603, 0.3416306362610464, 0.3350001426272467, 0.32836964899344706, 0.32173915535964737, 0.3151086617258477, 0.3084781680920481, 0.3018476744582484, 0.29521718082444875, 0.28858668719064906, 0.2819561935568494, 0.2753256999230498, 0.2686952062892501, 0.26206471265545045, 0.25543421902165075, 0.24880372538785112, 0.24217323175405142, 0.23554273812025178, 0.22891224448645214, 0.22228175085265245, 0.2156512572188528, 0.20902076358505312, 0.20239026995125348, 0.19575977631745378, 0.18912928268365414, 0.1824987890498545, 0.1758682954160548, 0.16923780178225517, 0.16260730814845548, 0.15597681451465584, 0.1493463208808562, 0.14271582724705656, 0.1360853336132568, 0.12945483997945717, 0.12282434634565753, 0.11619385271185789, 0.10956335907805814, 0.1029328654442585, 0.09630237181045886, 0.08967187817665923, 0.08304138454285959, 0.07641089090905984, 0.0697803972752602, 0.06314990364146056, 0.05651941000766092, 0.04988891637386128, 0.04325842274006153, 0.03662792910626189, 0.029997435472462253, 0.023366941838662614, 0.016736448204862975, 0.010105954571063225, 0.003475460937263627]}, 'GERAS-US': {'precision': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.5, 0.5, 0.5, 0.4, 0.4, 0.2222222222222222, 0.2222222222222222, 0.18181818181818182, 0.18181818181818182, 0.18181818181818182, 0.18181818181818182, 0.15384615384615385, 0.14285714285714285, 0.13333333333333333, 0.13333333333333333, 0.1, 0.09090909090909091, 0.09090909090909091, 0.10714285714285714, 0.1, 0.08571428571428572, 0.08108108108108109, 0.06976744186046512, 0.06521739130434782, 0.06, 0.05357142857142857, 0.047619047619047616, 0.04411764705882353, 0.041666666666666664, 0.0375, 0.03488372093023256, 0.044444444444444446, 0.04040404040404041, 0.03669724770642202, 0.04201680672268908, 0.0364963503649635, 0.040268456375838924, 0.04046242774566474, 0.03571428571428571, 0.037209302325581395, 0.03162055335968379, 0.02768166089965398, 0.025, 0.02197802197802198, 0.019753086419753086, 0.017278617710583154, 0.01556420233463035, 0.01391304347826087, 0.012403100775193798, 0.011347517730496455, 0.011658031088082901, 0.01060070671378092, 0.009782608695652175, 0.008955223880597015, 0.008379888268156424, 0.007712082262210797, 0.007142857142857143, 0.006574141709276844, 0.006118286879673691, 0.005660377358490566, 0.005238649592549476, 0.004880694143167028, 0.004582484725050916, 0.0044291338582677165, 0.004287756074321105, 0.004174397031539889, 0.0040853381752156154, 0.004016064257028112, 0.003909643788010426, 0.003854389721627409, 0.0038054968287526427, 0.0037751677852348995, 0.0037562604340567614, 0.003739094308267553, 0.0037220843672456576, 0.0037067545304777594, 0.0036991368680641184, 0.0036930652441526466, 0.0036915504511894994, 0.0036900369003690036, 0.0036900369003690036, 0.0036900369003690036, 0.0036900369003690036, 0.0036885245901639345], 'recall': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1111111111111111, 0.1111111111111111, 0.2222222222222222, 0.2222222222222222, 0.2222222222222222, 0.2222222222222222, 0.2222222222222222, 0.2222222222222222, 0.2222222222222222, 0.2222222222222222, 0.2222222222222222, 0.2222222222222222, 0.2222222222222222, 0.2222222222222222, 0.2222222222222222, 0.2222222222222222, 0.2222222222222222, 0.2222222222222222, 0.2222222222222222, 0.2222222222222222, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.4444444444444444, 0.4444444444444444, 0.4444444444444444, 0.5555555555555556, 0.5555555555555556, 0.6666666666666666, 0.7777777777777778, 0.7777777777777778, 0.8888888888888888, 0.8888888888888888, 0.8888888888888888, 0.8888888888888888, 0.8888888888888888, 0.8888888888888888, 0.8888888888888888, 0.8888888888888888, 0.8888888888888888, 0.8888888888888888, 0.8888888888888888, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'thresholds': [0.6052109823460612, 0.598808220249804, 0.5924054581535467, 0.5860026960572895, 0.5795999339610323, 0.573197171864775, 0.5667944097685178, 0.5603916476722606, 0.5539888855760033, 0.5475861234797461, 0.5411833613834889, 0.5347805992872317, 0.5283778371909744, 0.5219750750947173, 0.5155723129984601, 0.5091695509022028, 0.5027667888059456, 0.4963640267096884, 0.48996126461343115, 0.4835585025171739, 0.4771557404209167, 0.47075297832465945, 0.4643502162284022, 0.457947454132145, 0.45154469203588776, 0.44514192993963053, 0.4387391678433733, 0.43233640574711607, 0.42593364365085884, 0.4195308815546016, 0.41312811945834443, 0.4067253573620872, 0.40032259526583, 0.39391983316957274, 0.3875170710733155, 0.38111430897705834, 0.3747115468808011, 0.3683087847845439, 0.36190602268828664, 0.3555032605920294, 0.3491004984957722, 0.34269773639951495, 0.3362949743032577, 0.3298922122070005, 0.32348945011074326, 0.31708668801448603, 0.3106839259182288, 0.30428116382197157, 0.29787840172571434, 0.29147563962945716, 0.28507287753319993, 0.2786701154369427, 0.27226735334068547, 0.26586459124442824, 0.259461829148171, 0.2530590670519138, 0.24665630495565655, 0.24025354285939932, 0.23385078076314209, 0.2274480186668849, 0.22104525657062768, 0.21464249447437045, 0.20823973237811322, 0.201836970281856, 0.19543420818559876, 0.18903144608934153, 0.1826286839930843, 0.17622592189682706, 0.16982315980056983, 0.1634203977043126, 0.15701763560805543, 0.1506148735117982, 0.14421211141554097, 0.13780934931928374, 0.1314065872230265, 0.12500382512676927, 0.11860106303051204, 0.11219830093425481, 0.10579553883799758, 0.09939277674174041, 0.09299001464548318, 0.08658725254922595, 0.08018449045296872, 0.07378172835671148, 0.06737896626045425, 0.06097620416419702, 0.05457344206793979, 0.04817067997168256, 0.04176791787542533, 0.0353651557791681, 0.02896239368291087, 0.02255963158665364, 0.01615686949039641, 0.009754107394139178, 0.003351345297881947, -0.003051416798375284, -0.009454178894632514, -0.015856940990889634, -0.022259703087146865, -0.028662465183404057]}, 'GERAS-J': {'precision': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.5, 0.5, 0.6, 0.5, 0.5, 0.5, 0.42857142857142855, 0.375, 0.375, 0.375, 0.4, 0.3333333333333333, 0.3076923076923077, 0.21052631578947367, 0.18181818181818182, 0.15384615384615385, 0.125, 0.15789473684210525, 0.14634146341463414, 0.12244897959183673, 0.1111111111111111, 0.09836065573770492, 0.08333333333333333, 0.07894736842105263, 0.06976744186046512, 0.0625, 0.057692307692307696, 0.05982905982905983, 0.06060606060606061, 0.0547945205479452, 0.05194805194805195, 0.04519774011299435, 0.046632124352331605, 0.04390243902439024, 0.04090909090909091, 0.0411522633744856, 0.03816793893129771, 0.03424657534246575, 0.030864197530864196, 0.029490616621983913, 0.025056947608200455, 0.020484171322160148, 0.01634472511144131, 0.014302741358760428, 0.011822660098522168, 0.009942004971002486, 0.00847457627118644, 0.007233273056057866, 0.007322175732217573, 0.006871278057718736, 0.00650142218610321, 0.00577825929938606, 0.005503399158303658, 0.005067064083457526, 0.004727474972191324, 0.0044075706507648435, 0.004117219665778639, 0.004119935912108034, 0.0041457560549858176, 0.004010977411864049, 0.003916718202432488, 0.0038360589541691905, 0.003984857541342897, 0.003953350464518679, 0.003933136676499509, 0.00392156862745098, 0.003912363067292645, 0.003909304143862392, 0.00390625, 0.003903962521959789, 0.0039032006245121], 'recall': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05, 0.05, 0.05, 0.1, 0.1, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.35, 0.4, 0.4, 0.4, 0.4, 0.45, 0.45, 0.45, 0.5, 0.5, 0.5, 0.5, 0.55, 0.55, 0.55, 0.55, 0.6, 0.6, 0.6, 0.6, 0.6, 0.7, 0.75, 0.8, 0.8, 0.85, 0.85, 0.85, 0.85, 0.85, 0.9, 0.95, 0.95, 0.95, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'thresholds': [0.9463712784882564, 0.9364693138554097, 0.9265673492225628, 0.916665384589716, 0.9067634199568693, 0.8968614553240224, 0.8869594906911756, 0.8770575260583289, 0.867155561425482, 0.8572535967926352, 0.8473516321597885, 0.8374496675269416, 0.8275477028940948, 0.8176457382612481, 0.8077437736284012, 0.7978418089955545, 0.7879398443627077, 0.7780378797298609, 0.7681359150970142, 0.7582339504641673, 0.7483319858313205, 0.7384300211984738, 0.7285280565656269, 0.7186260919327802, 0.7087241272999334, 0.6988221626670865, 0.6889201980342398, 0.679018233401393, 0.6691162687685461, 0.6592143041356994, 0.6493123395028526, 0.6394103748700057, 0.629508410237159, 0.6196064456043122, 0.6097044809714653, 0.5998025163386186, 0.5899005517057718, 0.579998587072925, 0.5700966224400782, 0.5601946578072314, 0.5502926931743846, 0.5403907285415378, 0.530488763908691, 0.5205867992758442, 0.5106848346429974, 0.5007828700101506, 0.49088090537730383, 0.4809789407444571, 0.47107697611161026, 0.46117501147876344, 0.4512730468459167, 0.44137108221306987, 0.4314691175802231, 0.42156715294737623, 0.4116651883145295, 0.4017632236816827, 0.39186125904883584, 0.3819592944159891, 0.3720573297831423, 0.36215536515029556, 0.3522534005174487, 0.34235143588460193, 0.33244947125175517, 0.3225475066189083, 0.31264554198606154, 0.3027435773532148, 0.2928416127203679, 0.28293964808752115, 0.2730376834546744, 0.2631357188218275, 0.25323375418898075, 0.243331789556134, 0.23342982492328723, 0.22352786029044036, 0.2136258956575936, 0.20372393102474684, 0.19382196639189997, 0.1839200017590532, 0.17401803712620645, 0.16411607249335958, 0.15421410786051282, 0.14431214322766606, 0.13441017859481919, 0.12450821396197242, 0.11460624932912566, 0.1047042846962788, 0.09480232006343203, 0.08490035543058527, 0.0749983907977384, 0.06509642616489164, 0.05519446153204488, 0.04529249689919812, 0.03539053226635125, 0.02548856763350449, 0.015586603000657728, 0.005684638367810857, -0.004217326265035903, -0.014119290897882664, -0.024021255530729535, -0.03392322016357624]}, 'GERAS-II': {'precision': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.25, 0.25, 0.14285714285714285, 0.14285714285714285, 0.25, 0.25, 0.25, 0.25, 0.2, 0.18181818181818182, 0.16666666666666666, 0.16666666666666666, 0.125, 0.1111111111111111, 0.1111111111111111, 0.125, 0.11538461538461539, 0.1, 0.09375, 0.08333333333333333, 0.1, 0.08695652173913043, 0.0784313725490196, 0.07142857142857142, 0.06557377049180328, 0.05970149253731343, 0.05405405405405406, 0.04938271604938271, 0.04597701149425287, 0.041666666666666664, 0.037383177570093455, 0.03418803418803419, 0.029411764705882353, 0.03355704697986577, 0.03488372093023256, 0.031088082901554404, 0.027777777777777776, 0.023715415019762844, 0.020761245674740483, 0.018404907975460124, 0.01643835616438356, 0.014669926650366748, 0.01279317697228145, 0.01171875, 0.01048951048951049, 0.0093603744149766, 0.0084985835694051, 0.00902061855670103, 0.008130081300813009, 0.0074309978768577496, 0.0068762278978389, 0.0064516129032258064, 0.005988023952095809, 0.005537974683544304, 0.005131964809384164, 0.004797806716929404, 0.0044472681067344345, 0.0041841004184100415, 0.003979533826037522, 0.003794037940379404, 0.0037095919448860626, 0.004132231404958678, 0.004056795131845842, 0.00399002493765586, 0.003933136676499509, 0.0038498556304138597, 0.0038040893961008085, 0.003754106053496011, 0.0037243947858473, 0.0037122969837587007, 0.003693444136657433, 0.003676470588235294, 0.0036646816307833257, 0.003656307129798903, 0.0036496350364963502, 0.0036463081130355514, 0.0036446469248291574, 0.0036446469248291574, 0.0036446469248291574, 0.0036446469248291574, 0.0036429872495446266], 'recall': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.375, 0.375, 0.375, 0.375, 0.375, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.625, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'thresholds': [0.6053323902891427, 0.5989286400721309, 0.5925248898551191, 0.5861211396381073, 0.5797173894210955, 0.5733136392040837, 0.5669098889870721, 0.5605061387700603, 0.5541023885530485, 0.5476986383360367, 0.5412948881190249, 0.5348911379020131, 0.5284873876850014, 0.5220836374679896, 0.5156798872509778, 0.509276137033966, 0.5028723868169542, 0.4964686365999425, 0.4900648863829307, 0.48366113616591894, 0.47725738594890715, 0.4708536357318954, 0.46444988551488364, 0.45804613529787186, 0.4516423850808601, 0.4452386348638483, 0.4388348846468365, 0.4324311344298247, 0.42602738421281294, 0.41962363399580116, 0.4132198837787894, 0.40681613356177765, 0.40041238334476587, 0.3940086331277541, 0.38760488291074235, 0.38120113269373057, 0.3747973824767188, 0.368393632259707, 0.3619898820426952, 0.35558613182568344, 0.34918238160867165, 0.34277863139165987, 0.33637488117464814, 0.32997113095763636, 0.3235673807406246, 0.3171636305236128, 0.310759880306601, 0.3043561300895892, 0.2979523798725775, 0.2915486296555657, 0.28514487943855393, 0.27874112922154215, 0.27233737900453037, 0.2659336287875186, 0.2595298785705068, 0.2531261283534951, 0.2467223781364833, 0.2403186279194715, 0.23391487770245972, 0.22751112748544794, 0.22110737726843616, 0.21470362705142443, 0.20829987683441265, 0.20189612661740086, 0.19549237640038908, 0.1890886261833773, 0.1826848759663655, 0.17628112574935373, 0.169877375532342, 0.16347362531533022, 0.15706987509831843, 0.15066612488130665, 0.14426237466429487, 0.13785862444728308, 0.13145487423027136, 0.12505112401325957, 0.11864737379624779, 0.11224362357923601, 0.10583987336222422, 0.09943612314521244, 0.09303237292820066, 0.08662862271118887, 0.08022487249417709, 0.07382112227716531, 0.06741737206015364, 0.06101362184314185, 0.05460987162613007, 0.048206121409118285, 0.0418023711921065, 0.03539862097509472, 0.028994870758082936, 0.022591120541071152, 0.01618737032405937, 0.009783620107047586, 0.0033798698900358026, -0.0030238803269759806, -0.009427630543987653, -0.015831380760999436, -0.02223513097801122, -0.02863888119502298]}, 'PREVENT Dementia': {'precision': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.125, 0.1111111111111111, 0.1111111111111111, 0.1111111111111111, 0.2857142857142857, 0.26666666666666666, 0.25, 0.25, 0.2, 0.19047619047619047, 0.19047619047619047, 0.19047619047619047, 0.18181818181818182, 0.13793103448275862, 0.13793103448275862, 0.11428571428571428, 0.10810810810810811, 0.08888888888888889, 0.07407407407407407, 0.07575757575757576, 0.06666666666666667, 0.05555555555555555, 0.04807692307692308, 0.06153846153846154, 0.056962025316455694, 0.05, 0.04878048780487805, 0.04405286343612335, 0.038314176245210725, 0.03496503496503497, 0.031446540880503145, 0.028328611898016998, 0.02544529262086514, 0.022123893805309734, 0.021739130434782608, 0.0196078431372549, 0.018121911037891267, 0.017857142857142856, 0.01634877384196185, 0.01625, 0.01463963963963964, 0.014198782961460446, 0.012785388127853882, 0.011466011466011465, 0.010393466963622866, 0.010337698139214336, 0.009129640900791236, 0.008324084350721421, 0.007462686567164179, 0.0066725978647686835, 0.006331618519984171, 0.005621925509486999, 0.005029864822382898, 0.004435819240365955, 0.003914851969659897, 0.003480530780944094, 0.003073967339097022, 0.0027739251040221915, 0.002508230130114438, 0.0024369266055045873, 0.0023837902264600714, 0.0023321468025039893, 0.0021701884637350087, 0.002047634443366742, 0.0020364524997454436, 0.0020337013364323067, 0.0021321961620469083, 0.0021447721179624667, 0.002168821028888696, 0.0021102388790411077, 0.0020637279181112763, 0.0020249473513688646, 0.001999360204734485, 0.001977691638319753, 0.0019609381127931604, 0.001950991103480568, 0.001943105860407275, 0.001938285005427198, 0.0019363333591511116, 0.001934385639121015, 0.0019337871287128713, 0.0019331889885555213], 'recall': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16, 0.2, 0.2, 0.2, 0.2, 0.32, 0.36, 0.36, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.44, 0.44, 0.44, 0.48, 0.48, 0.52, 0.52, 0.56, 0.56, 0.56, 0.56, 0.6, 0.6, 0.6, 0.6, 0.6, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.68, 0.72, 0.76, 0.76, 0.76, 0.8, 0.84, 0.92, 0.96, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'thresholds': [0.7325163414832012, 0.7249623092523217, 0.7174082770214423, 0.7098542447905627, 0.7023002125596832, 0.6947461803288038, 0.6871921480979243, 0.6796381158670448, 0.6720840836361653, 0.6645300514052859, 0.6569760191744063, 0.6494219869435268, 0.6418679547126473, 0.6343139224817679, 0.6267598902508884, 0.6192058580200088, 0.6116518257891294, 0.6040977935582499, 0.5965437613273704, 0.5889897290964909, 0.5814356968656114, 0.573881664634732, 0.5663276324038524, 0.558773600172973, 0.5512195679420935, 0.543665535711214, 0.5361115034803345, 0.528557471249455, 0.5210034390185755, 0.513449406787696, 0.5058953745568165, 0.4983413423259371, 0.49078731009505755, 0.483233277864178, 0.47567924563329855, 0.4681252134024191, 0.4605711811715396, 0.4530171489406601, 0.4454631167097806, 0.43790908447890114, 0.4303550522480216, 0.42280102001714215, 0.4152469877862627, 0.40769295555538315, 0.4001389233245037, 0.3925848910936242, 0.3850308588627447, 0.3774768266318652, 0.36992279440098574, 0.3623687621701062, 0.35481472993922675, 0.3472606977083472, 0.33970666547746775, 0.3321526332465883, 0.32459860101570875, 0.3170445687848293, 0.3094905365539498, 0.3019365043230703, 0.2943824720921908, 0.28682843986131135, 0.2792744076304318, 0.27172037539955235, 0.2641663431686729, 0.25661231093779335, 0.24905827870691388, 0.2415042464760344, 0.23395021424515489, 0.22639618201427536, 0.2188421497833959, 0.21128811755251642, 0.20373408532163695, 0.19618005309075748, 0.188626020859878, 0.18107198862899843, 0.17351795639811896, 0.16596392416723948, 0.15840989193636001, 0.15085585970548054, 0.14330182747460107, 0.1357477952437215, 0.12819376301284202, 0.12063973078196255, 0.11308569855108308, 0.10553166632020361, 0.09797763408932414, 0.09042360185844456, 0.08286956962756509, 0.07531553739668562, 0.06776150516580615, 0.060207472934926676, 0.052653440704047205, 0.045099408473167624, 0.03754537624228815, 0.029991344011408683, 0.022437311780529212, 0.014883279549649742, 0.007329247318770271, -0.0002247849121093104, -0.007778817142988781, -0.015332849373868236]}}



results_openai = {
    'GERAS-I': [0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273,
                0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273,
                0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273,
                0.7272727272727273, 0.8181818181818182, 0.9090909090909091, 0.9090909090909091, 0.9090909090909091],
    'GERAS-US': [0.7777777777777778, 0.7777777777777778, 0.7777777777777778, 0.7777777777777778, 0.7777777777777778,
                 0.7777777777777778, 0.7777777777777778, 0.7777777777777778, 0.7777777777777778, 0.8888888888888888,
                 0.8888888888888888, 0.8888888888888888, 0.8888888888888888, 0.8888888888888888, 1.0, 1.0, 1.0, 1.0,
                 1.0, 1.0],
    'GERAS-J': [0.6, 0.8, 0.85, 0.85, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],
    'GERAS-II': [0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.875, 0.875, 0.875, 0.875, 0.875, 1.0, 1.0, 1.0,
                 1.0, 1.0, 1.0],
    'PREVENT Dementia': [0.5217391304347826, 0.6086956521739131, 0.6521739130434783, 0.6956521739130435,
                         0.782608695652174, 0.782608695652174, 0.782608695652174, 0.782608695652174, 0.8260869565217391,
                         0.8695652173913043, 0.9130434782608695, 0.9130434782608695, 0.9130434782608695,
                         0.9130434782608695, 0.9130434782608695, 0.9130434782608695, 0.9130434782608695,
                         0.9130434782608695, 0.9130434782608695, 0.9130434782608695]}

results_linq = {
    'GERAS-I': [0.45454545454545453, 0.5454545454545454, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273,
                0.7272727272727273, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182,
                0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182,
                0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.9090909090909091],
    'GERAS-US': [0.3333333333333333, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666,
                 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666,
                 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666,
                 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666],
    'GERAS-J': [0.4, 0.55, 0.7, 0.7, 0.7, 0.7, 0.75, 0.75, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.85,
                0.85],
    'GERAS-II': [0.25, 0.375, 0.5, 0.625, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75,
                 0.75, 0.75, 0.75],
    'PREVENT Dementia': [0.30434782608695654, 0.30434782608695654, 0.43478260869565216, 0.4782608695652174,
                         0.4782608695652174, 0.4782608695652174, 0.4782608695652174, 0.4782608695652174,
                         0.5217391304347826, 0.5217391304347826, 0.5217391304347826, 0.5217391304347826,
                         0.5217391304347826, 0.5652173913043478, 0.5652173913043478, 0.5652173913043478,
                         0.6521739130434783, 0.6521739130434783, 0.6956521739130435, 0.6956521739130435]}

results_gwen3 = {
    'GERAS-I': [0.5454545454545454, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364,
                0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364,
                0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273,
                0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273],
    'GERAS-US': [0.4444444444444444, 0.4444444444444444, 0.4444444444444444, 0.4444444444444444, 0.4444444444444444,
                 0.4444444444444444, 0.4444444444444444, 0.4444444444444444, 0.4444444444444444, 0.4444444444444444,
                 0.4444444444444444, 0.4444444444444444, 0.4444444444444444, 0.4444444444444444, 0.4444444444444444,
                 0.4444444444444444, 0.4444444444444444, 0.4444444444444444, 0.4444444444444444, 0.4444444444444444],
    'GERAS-J': [0.45, 0.45, 0.5, 0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.6, 0.65, 0.65, 0.65, 0.7, 0.7, 0.7,
                0.7, 0.75],
    'GERAS-II': [0.375, 0.375, 0.375, 0.375, 0.375, 0.375, 0.375, 0.375, 0.375, 0.375, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,
                 0.5, 0.5, 0.5, 0.5],
    'PREVENT Dementia': [0.34782608695652173, 0.34782608695652173, 0.391304347826087, 0.43478260869565216,
                         0.43478260869565216, 0.43478260869565216, 0.43478260869565216, 0.43478260869565216,
                         0.4782608695652174, 0.4782608695652174, 0.5217391304347826, 0.5652173913043478,
                         0.5652173913043478, 0.5652173913043478, 0.5652173913043478, 0.5652173913043478,
                         0.5652173913043478, 0.5652173913043478, 0.5652173913043478, 0.5652173913043478]}

all_mini_lm = {
    'GERAS-I': [0.45454545454545453, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273,
                0.7272727272727273, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182,
                0.9090909090909091, 0.9090909090909091, 0.9090909090909091, 0.9090909090909091, 0.9090909090909091,
                0.9090909090909091, 0.9090909090909091, 0.9090909090909091, 0.9090909090909091, 0.9090909090909091],
    'GERAS-US': [0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.6666666666666666, 0.7777777777777778,
                 0.7777777777777778, 0.7777777777777778, 0.8888888888888888, 0.8888888888888888, 0.8888888888888888,
                 0.8888888888888888, 0.8888888888888888, 0.8888888888888888, 0.8888888888888888, 0.8888888888888888,
                 0.8888888888888888, 0.8888888888888888, 0.8888888888888888, 0.8888888888888888, 0.8888888888888888],
    'GERAS-J': [0.7, 0.85, 0.9, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],
    'GERAS-II': [0.5, 0.5, 0.5, 0.5, 0.625, 0.625, 0.625, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75,
                 0.875, 0.875, 0.875],
    'PREVENT Dementia': [0.43478260869565216, 0.43478260869565216, 0.6086956521739131, 0.6521739130434783,
                         0.7391304347826086, 0.8260869565217391, 0.8695652173913043, 0.8695652173913043,
                         0.9130434782608695, 0.9130434782608695, 0.9130434782608695, 0.9130434782608695,
                         0.9130434782608695, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}

plot_top_n_accuracies(accuracies=results_linq, vectorizer_name="Linq-Embed-Mistral", save_path="plots")
plot_top_n_accuracies(accuracies=results_openai, vectorizer_name="OpenAI", save_path="plots")
plot_top_n_accuracies(accuracies=results_gwen3, vectorizer_name="Gwen3", save_path="plots")
plot_top_n_accuracies(accuracies=all_mini_lm, vectorizer_name="MiniLM", save_path="plots")

all_accuracies = {
    "OpenAI": results_openai,
    "Linq-Embed-Mistral": results_linq,
    "Gwen3": results_gwen3,
    "MiniLM": all_mini_lm
}

df_summary = summarize_top1_accuracies(all_accuracies, save_path="plots")
print(df_summary)

plot_topn_per_cohort(all_accuracies, title_prefix="Vectorizer Benchmark", save_path="plots")

plot_precision_recall_curves(pr_results=pr_openai, save_path="plots")